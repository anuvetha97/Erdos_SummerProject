{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70746001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b153ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from each file\n",
    "file_paths = [\"index_history_new.pkl\", \"saved_indexes.pkl\", \"saved_symbols.pkl\", \"ticker_history_new.pkl\", \"event_clean.pkl\"]\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, \"rb\") as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "        data_dict[path] = data\n",
    "\n",
    "# Access the loaded data\n",
    "index_history = data_dict[\"index_history_new.pkl\"] \n",
    "saved_indices = data_dict[\"saved_indexes.pkl\"]\n",
    "saved_tickers = data_dict[\"saved_symbols.pkl\"]\n",
    "ticker_history = data_dict[\"ticker_history_new.pkl\"]\n",
    "event_history = data_dict[\"event_clean.pkl\"]\n",
    "\n",
    "dict_tickers = ticker_history.copy()\n",
    "dict_index = index_history.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ffc0e",
   "metadata": {},
   "source": [
    "1. index_history has the last 5 years of index data for top 20 indices (from May 2019 - May 2023)\n",
    "2. saved_indices has the top 20 index tickers\n",
    "3. saved_tickers has the top 100 NASDAQ tickers\n",
    "4. ticker_history has the last 5 years stock data for top 100 NASDAQ tickers (from May 2019 - May 2023)\n",
    "5. event_history has the earnings date info from Jan 2019 until December 2023 for the saved_tickers\n",
    "\n",
    "We might have to include data for index_history and ticker_history from Jan 2019 to May 2019 since the earnings data starts from Jan 2019-Dec 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd908fa",
   "metadata": {},
   "source": [
    "\n",
    "1. index_history : dict with keys as index tickers. Value is a dataframe with 5 years of history (Date,Open,High,Low,Close,Volume,Dividends,Stock Splits)\n",
    "2. saved_indices : list of keys of index_history\n",
    "3. saved_tickers : list of keys of ticker_history\n",
    "4. ticker_history : dict with keys as NASDAQ100 stock tickers. Value is a dataframe with 5 years of history (Date,Open,High,Low,Close,Volume,Dividends,Stock Splits)\n",
    "5. event_history : dict with keys as NASDAQ100 stock tickers. Value is a dataframe with 5 years of history (Date,EPS Estimate, Reported EPS, Surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c080920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big = yf.Tickers(saved_tickers)\n",
    "# dict_tickers_new = {i:big.tickers[i].history(period = \"66mo\") for i in saved_tickers}\n",
    "# major_indices = yf.Tickers(saved_indices)\n",
    "# dict_indices_new = {i:major_indices.tickers[i].history(period = \"66mo\") for i in saved_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ticker_history_new.pkl', 'wb') as f:\n",
    "#     pickle.dump(dict_tickers_new, f)\n",
    "# with open('index_history_new.pkl', 'wb') as f:\n",
    "#     pickle.dump(dict_indices_new, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f21e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_indices = ['^GSPC','^DJI','^IXIC','^NYA','^XAX','^RUT']\n",
    "closing_time_from_midnight = pd.DateOffset(hours=16) # Closing time of NYSE(4pm). Closing time matters because we want\n",
    "# to determine if the closing time is before or after event. # For pre-market earning events, \n",
    "# the 'before' data should not include the data from that day. \n",
    "\n",
    "closing_time_from_midnight_ind = {}\n",
    "us_indices = ['^GSPC','^DJI','^IXIC','^NYA','^XAX','^RUT']\n",
    "for ind in us_indices:\n",
    "    closing_time_from_midnight_ind[ind] = pd.DateOffset(hours=16) # Closing time of NYSE\n",
    "closing_time_from_midnight_ind['^VIX'] = pd.DateOffset(hours=15.25)\n",
    "closing_time_from_midnight_ind['^BUK100P'] = pd.DateOffset(hours=17.5)\n",
    "closing_time_from_midnight_ind['^FTSE'] = pd.DateOffset(hours=16.5)\n",
    "closing_time_from_midnight_ind['^GDAXI'] = pd.DateOffset(hours=18)\n",
    "closing_time_from_midnight_ind['^FCHI'] = pd.DateOffset(hours=17.5)\n",
    "closing_time_from_midnight_ind['^STOXX50E'] = pd.DateOffset(hours=18)\n",
    "closing_time_from_midnight_ind['^N100'] = pd.DateOffset(hours=17.5)\n",
    "closing_time_from_midnight_ind['^BFX'] = pd.DateOffset(hours=17.5)\n",
    "closing_time_from_midnight_ind['IMOEX.ME'] = pd.DateOffset(hours=16)\n",
    "closing_time_from_midnight_ind['^N225'] = pd.DateOffset(hours=15)\n",
    "closing_time_from_midnight_ind['^HSI'] = pd.DateOffset(hours=16)\n",
    "closing_time_from_midnight_ind['000001.SS'] = pd.DateOffset(hours=15)\n",
    "closing_time_from_midnight_ind['399001.SZ'] = pd.DateOffset(hours=15)\n",
    "closing_time_from_midnight_ind['^STI'] = pd.DateOffset(hours=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be9a00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "indices = saved_indices\n",
    "\n",
    "for sym in event_history:\n",
    "    dum = []\n",
    "    event_date = event_history[sym].index\n",
    "    month_before_event_date = event_date - pd.DateOffset(months=1)\n",
    "    week_after_event_date = event_date + pd.DateOffset(weeks=1)\n",
    "        \n",
    "    for j in range(len(event_history[sym])):\n",
    "        dic = {\"Before\":0, \"After\":0, \"Earning\":0}\n",
    "        dic['Earning'] = event_history[sym].iloc[[j]]\n",
    "        \n",
    "        ticker_closing = ticker_history[sym].index+closing_time_from_midnight\n",
    "        dfb = ticker_history[sym][[\"Close\"]][(ticker_closing>month_before_event_date[j]) & (ticker_closing<=event_date[j])]\n",
    "        dfb[\"Closing DateTime\"] = dfb.index+closing_time_from_midnight\n",
    "        dfb = dfb[[\"Closing DateTime\",\"Close\"]]\n",
    "        dfb = dfb.rename(columns = {\"Close\":sym})\n",
    "        dfb = dfb.set_index('Closing DateTime')\n",
    "        for ind in indices:\n",
    "            index_closing = index_history[ind].index+closing_time_from_midnight_ind[ind]\n",
    "            dfbi = index_history[ind][[\"Close\"]][(index_closing>month_before_event_date[j]) & (index_closing<=event_date[j])]            \n",
    "            dfbi[\"Closing DateTime\"] = dfbi.index+closing_time_from_midnight_ind[ind]\n",
    "            dfbi = dfbi.rename(columns={\"Close\":ind})\n",
    "            dfb = dfb.join(dfbi.set_index(\"Closing DateTime\"),on=\"Closing DateTime\",how=\"outer\")\n",
    "        dfb.index = range(len(dfb))\n",
    "        dic[\"Before\"] = dfb\n",
    "\n",
    "        ticker_closing = ticker_history[sym].index+closing_time_from_midnight\n",
    "        dfa = ticker_history[sym][[\"Close\"]][(ticker_closing>event_date[j]) & (ticker_closing<=week_after_event_date[j])]\n",
    "        dfa[\"Closing DateTime\"] = dfa.index+closing_time_from_midnight\n",
    "        dfa = dfa[[\"Closing DateTime\",\"Close\"]]\n",
    "        dfa = dfa.rename(columns = {\"Close\":sym})\n",
    "        dfa = dfa.set_index('Closing DateTime')\n",
    "        for ind in indices:\n",
    "            index_closing = index_history[ind].index+closing_time_from_midnight_ind[ind]\n",
    "            dfai = index_history[ind][[\"Close\"]][(index_closing>event_date[j]) & (index_closing<=week_after_event_date[j])]            \n",
    "            dfai[\"Closing DateTime\"] = dfai.index+closing_time_from_midnight_ind[ind]\n",
    "            dfai = dfai.rename(columns={\"Close\":ind})\n",
    "            dfa = dfa.join(dfai.set_index(\"Closing DateTime\"),on=\"Closing DateTime\",how=\"outer\")\n",
    "        dfa.index = range(len(dfa))\n",
    "        dic[\"After\"] = dfa\n",
    "        \n",
    "        dum.append(dic)\n",
    "    d[sym] = dum\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebf519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1mobef_1wkaft_earnings_data_clean_new.pkl', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b45fb8",
   "metadata": {},
   "source": [
    "This pickle file is a dictionary whose keys are Tickers with values being a list of dictionaries. Each of these dictionaries has an 'earnings' key with value as earnings dataframe, 'before'('after') key with value dataframe of ticker's and indices closing data for 1 month before (1 week after) the earnings event. \n",
    "\n",
    "The 'before' dataframe has columns as 'Closing DateTime', 'Ticker', all indices. \n",
    "\n",
    "The Closing DateTime is the list of all closing times corresponding to dates in the 1 month window for ALL the indices (noting the timezone diff for each index as well as the local closing times). \n",
    "\n",
    "For example, 2023-12-13 16:00:00-05:00 will have a valid entry only for 'Ticker', US indices as only those would close at the corresponding time. All others would be nan since they don't close at the same time. For example, STI corresponds to an index in Singapore which closes at 2023-12-13 04:00:00-05:00. They have a different time. Hence, we add the closing price of STI to the row corresponding to that time. \n",
    "\n",
    "If we want to access the dates and closing prices of ^GSPC before ADBE's most recent earning, we can use the following code to get the corresponding dataframe.  \n",
    "\n",
    "d1 = d['ADBE'][0]['Before']\n",
    "\n",
    "d1[pd.notna(d1['^GSPC'])][['Closing DateTime','^GSPC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732ea73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
